
GAN を作ろう
2019/12/07

[実装]
	[参考]
		cf. 今さら聞けないGAN（1）　基本構造の理解
			https://qiita.com/triwave33/items/1890ccc71fab6cbca87e

			[abst]
				GAN のコンセプトは様々な例もあり理解しやすく、
					学習したモデルから新たに絵や文章などを作り出せることは
					「これぞ人工知能」感を醸し出しています。
				知ったかぶってしまうくせに、
					ソースコードレベルでの動作については実は良くわかっていない。
				チュートリアルを実行しても、参考文献読んでもなんとなく
					「この行は hoge をしているのだなぁ」ということはわかるのですが
					そもそも「 GAN の基本思想を理解した上で
						なぜこのコーディングになっているのか」が掴めないため
							自分の適用させたい問題に対して
							どこを修正すれば良いのかわからない
							新しいアルゴリズムが出てきたときに
								どこを修正すれば良いのかわからない
					# 図星..
				この記事では、自分自身の経験のもと
					GAN の概念をどうコーディングに落とし込むかを解説したいと思います。
						理論についてはあえて深入りせず
						GAN の考え方とコードの対応関係を解説できたらと思います。
	[孫引き]
		Generative Adversarial Networks(GAN)を勉強して、kerasで手書き文字生成する
			http://yusuke-ujitoko.hatenablog.com/entry/2017/05/08/010314
		はじめてのGAN
			https://elix-tech.github.io/ja/2017/02/06/gan.html
	[GANについてなんとなく分かっていること]
		生成モデルである (絵を描いたりできる)
		生成者と識別者を競わせる
		パラメータチューニングが難しい
		数字を書いたりベッドルームを生成したりできる
		線画に着色したり、単語から画像を生成したりできる
		様々な GAN 亜種があり、現在進行形で増えている
			# これってもはや DL / NN 全体に対して言えることでは..??
		とりあえずチュートリアルを実行している
	[GANについてよく分からないこと]
		生成者と識別者のネットワークの繋ぎ方
		生成させるデータの元となるデータ
		loss 関数の中身の解釈
		GAN の種類と使い分け
		学習した生成モデルのコントロール
		mnist を学習したが、どうやって "1" と "5" を書き分ける？
		exampleを実行できたが、各行の表す意味
		意味は理解できるが、その記述に至った思考過程
	[目的]
		GAN の実装面での基本コンセプトを理解し、一から実装できるようになる
	[内容]
		GAN のネットワーク構造と
			入力データ & 正解ラベル, loss 関数について
	[前提知識]
		MLP, CNN を用いた識別モデルを Keras で理解、実装できる
		numpy.ndarrayの知識
			# たぶん OK
	[使用データ]
		MNIST データセット
			shape == (datasize, 28, 28, 1)
	[基本構造 (flow) ]
			 +-----------+				+---------------+
		z => | Generator |	=> image => | Descriminator | => classifer
		  	 +-----------+	   		 	+---------------+

		[GANの基本構造]
			上図:
				四角で囲んだモジュールが
					生成器 (Generator) および識別器 (Discriminator)
				丸で囲んだ変数が
					各モジュールの入出力となる変数を示しています。

			まず Generator は
				潜在変数と言われる値 (z) を入力値として受け取り、
				画像データ (img) を出力します。
					通常 z は (mnistの場合) 100次元ほどの各要素が
						0 から 1 までの値をとる変数で
						一様分布や正規分布からランダムサンプリングされます。
							つまり、この潜在変数 z が
								生成モデルから画像を生成するための「種」となります。
			Discriminator は
				画像データ (img) を入力値として取り
				そのデータが本物か
					それとも Generator から生成 (捏造) されたデータか
						を出力値 (classifer) として識別します。
						出力値は
							本物である場合 1
							偽物である場合 0 として
								その確率を連続値として返します。
								# いや確率が連続値で
								#	予測クラスは離散値でしょ。
								#		この書き方は誤解を招きそうというか
								#		正しく受け取られない気が..
			データを示す丸は
				データの "実体" ではなく
				データを流し込むための "窓口" だと思ってください。
					# Tensorflow でいう Placeholder

		[Discriminator (識別器)の学習]
			識別器は
				画像 (img) を入力データとして、
				予想結果 (偽物か本物か) を出力するので、
					教師データは「画像」と「その偽物か本物かのラベル」になります。
						# そう考えると教師「あり」学習とも言える??
						#	でもこの label を使うのは Descriminator なのだから
						#	目的である Generator は label なし
						#		(全部本物にする! という目標)
						#		ということから教師「なし」学習なのか..
				すなわち
					本物の画像を入力した時には 1 の正解ラベルを
					偽物を入力した時には 0 の正解ラベルを与えます。

				偽物の画像を生成するためには
					生成器の入力値 z に乱数から発生させたデータ (noise) を与えます。
						Generator から生成画像を実際に発生させ
							# predictメソッドを使います <= なるほど??
						生成された偽物画像を入力に使います。
							!! ここで Generator は画像を生成させるために用いただけで、
							!! 	学習対象の Discriminator とは "完全に分離されている"
							!!		ということに注意してください。
							!!	Generator はこの場合 Discriminator の学習とは無関係です。
				データセットにある本物の画像の場合は、
					単純に識別器の入力に実データを流し込めば OK
		[Generatorの学習]
			GAN の最終出力 (目標) は
				"画像が本物であるかどうか (の確率) を表す変数" であるため
					Generator の学習時にも classifer を目的変数にとります。
						!! このあたりが、同じ生成モデルではありますが、
						!!	目的変数に自分自身の入力データをとる
						!! 	VAE (Valiational Auto Encoder) との違いになります。
						!!		だそうです..
					従って、Genarator の学習時には
						Discriminator までを含めたネットワークを用います。
						これを図中では Combined ネットワークとして表しています。
-- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< --
					z: Noise
				(Latent variable)
					|
					v													___
				+-----------+											^
				| Generator |  <= 学習する対象							|
				+-----------+											|
					|													|
					v													|
				Fake image			Real image						Combined
					|					|							Network
					+-------------------+								|
							|											|
							v											|
						Desctiminator  # Generator 学習時, 重みは凍結	|
							|											|
							v											v
						 0 (Fake) / 1 (Real)							___
-- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< --

   	  	   	  	   	ただし、ここではあくまで Genarator を学習させたいため
						Discriminator の重みを固定させる必要があります。
							これは、Discrminator のオプションを
								trainable=Falseにすることで達成されます。
								# 転移学習のあれと同じ..
						入力データは乱数によって生成された値 noise (z) です。
				これで Combined ネットワークを学習させることで
					Genarator だけをうまく学習させることができます。

				ここで一つだけトリックを使います。
					noise から Genarator を用いて生成された画像は当然偽物なので、
						本来正解ラベルは 0 なのですが
							ここでは本物 (1) のラベルをつけます。
								なぜなら Generator の目的は
									Discriminatorを騙すことなので
									識別結果が "本物" と判定されるほうが
									(Generatorにとっての) loss 関数の値が
									小さくなる方向に進むからです。

				Discriminator, Generator の学習ともに
					予想と正解が一致するときに値が小さくなるような loss 関数を用いて
						その関数を最小化するように学習します。
							ラベルは 0, 1 の二値分類ですので
							loss関数として binary crossentropy を用いることができます。

	[コード]
		-> source.py

	[設計]
		GAN クラスを定義し
			コンストラクタ (attribute) に GAN の基本構造を定義
				attributes:
					入力画像の shape:
						mnist なので 28*28*1チャンネル (白黒) 
					学習に用いる optimizer
				GAN 基本構造:
					# メンバ変数として定義
					discriminator 変数を宣言し
						build_discriminator メソッドの返り値を格納します。
						build_discriminator は
							入力: mnist data の shape をとり
							出力: sigmoid 関数により
								最終的に [0, 1] を出力するモデルです。
					build_generator メソッド
						=> generator 変数を宣言
					# オリジナルでは
					#	generator もコンパイルしていますが
					# 	generator 単体では学習しないので
					#		ここでのコンパイルは必要ありません。
					# generatorの学習時には
					#	generator単体ではなく
					#		あくまで discriminator を連結した
					#		combined ネットワークを用いる。
					combined ネットワークも作成
						generator と discriminator を直列に繋ぎます。
						ここでは、多少冗長ですが二通りの方法を紹介します。
							1つ目は、先で定義した model 名を用いて
								新しい combined model を定義する方法です。
									# コードの buildCombined1() メソッドがこれに対応
									Sequential( [self.generator, self.discriminator] )
										のように sequential モデルに
											generator と descriminator をリスト形式で繋ぎ
											入力することで 2つのモデルを直列に繋げる
												モデルを指定することで
													そのモデルの入出力が決まりますから、
														あるモデルの出力が
														次のリストのモデルの入力に
														引き渡されていくことになる。
														この際、前段の出力の形と
														入力の形は一致している必要がある
							2つ目は、2つのモデルの出入力の間に変数を噛ませて繋ぎ
								全体を新しい combined model として定義する方法
									# これは buildCombined2() メソッドに対応。
									generator の入力 z を Inputメソッドを用いて宣言し、
										# Input method:
										# 	keras.layers, Input
										generator からの出力を変数 img に代入します。
									さらに生成画像 img を discriminator に渡した出力を
										pred として、データの通り道を作ってやります。
								最終的なモデルの宣言は
									Model メソッドに
										# Model method:
										# 	keras.models, Models
										最初の入力と
										最後の出力を指定することで達成されます。
							記述がシンプルなのは 1つ目の方法ですが
								実際のモデル構造を入出力を意識しながら記述しているのは
									2つめ目の方法です。
									モデルの分岐、合流など複雑なモデルを扱う場合は
										後者の方が適しています。
	[loss関数]
		Descriminator, Generator
		入力データ、正解ラベルの関係
		それに対応するloss関数について
			# 本参考では GAN論文に記載されている loss 関数を用いているらしい。

		まずは Discriminator からですが
			Generator を固定した上で loss関数を最大化します。
			右辺第1項は本物データを用いるケースです。
			この項を最大化するにはlogの内部を最大化、
			すなわちDiscriminatorの識別結果として1を出力させるよう学習させます。

			右辺第2項は、Generator により生成されたデータを示します。
				log内部を最大化するためには
				Discriminator の出力を最小化
					つまり 0 を出力するようにすれば良いです。
					これは Discriminator の学習のところで触れた
					入力データの組み合わせと正解ラベルの組み合わせに一致します。

		次に Generator についてです。
			Discriminator は固定で Generator のみに依存するので第2項のみを考えます。
			Generator からの出力について最小化をするので
			対数項の中身が 1 になるように学習させたいことがわかります。
			これは Generator の学習のフェーズで Generator から生成した偽物の画像に、
			本物のラベル (1) をつけて学習させることに対応します。

		やや観念的な説明になりましたが、
			GAN のロス関数の定義と
			実装で用いた各ネットワークの loss関数の対応がわかると思います。

	[学習]
		論文のアルゴリズム通りに実装しています。
		論文と少し違うところは discriminator の学習時に
			教師データ (本物データ) と
			generator から生成した偽物データを別々に学習させているところです。

		今回の実装では、実はあまり影響はないですが、
			GAN を効率よく学習させるための手法として
				Batch Normalization という手法があります。
			入力データをミニバッチ単位で正規化する手法で、
				本物データと
				(特に学習初期のほとんど乱数のような) 生成データを混ぜて正規化することは
				好ましくないため、分けて処理していると考えられます。
				# 好ましくない??
