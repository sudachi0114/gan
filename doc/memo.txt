
GAN を作ろう
2019/12/07

[前段]
	(C)NN の学習理解がしたい。
		中間層とかノードのもっとも反応する画像
			などを描画したい。
				しかし、現状 NN からの出力を受けられるのは (仕方を知っているのは)
					予測のラベルだけ..
			Deep Learning で生成技術と言ったら GAN でしょ。
				作るか..
					という経緯。
[導入と概要]
	GAN という言葉って何?
		Generative Adversarial Nets の略
			日本語でいうと「敵対的生成ネットワーク」
		> GANは生成モデルの一種であり、
		>	データから特徴を学習することで、
		>	実在しないデータを生成したり、存在するデータの特徴に沿って変換できる。
		>
		> GANは、正解データを与えることなく特徴を学習する
		>	「教師なし学習」の一手法として注目されている。
		>		# そうなんだ..
		>		#	教師なし学習だとは知らなかった..
		>	そのアーキテクチャの柔軟性から、アイデア次第で広範な領域に摘用できる。
		>	応用研究や理論的研究も急速に進んでおり、今後の発展が大いに期待されている。
		> 引用元:
		>	https://www.imagazine.co.jp/gan%EF%BC%9A%E6%95%B5%E5%AF%BE%E7%9A%84%E7%94%9F%E6%88%90%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%A8%E3%81%AF%E4%BD%95%E3%81%8B%E3%80%80%EF%BD%9E%E3%80%8C%E6%95%99%E5%B8%AB/

	[参考]
		GANについて概念から実装まで
			https://qiita.com/taku-buntu/items/0093a68bfae0b0ff879d

		[GANの仕組み]
			GAN 全体の仕組みについて概説します。
				GAN は Generator (生成器) と Discriminator (弁別|識別器)
					という別々の学習モデルを用います。
				この Generator と Discriminator の関係は、しばしば
					紙幣の偽装者 (Generator) と、
					その紙幣の真贋を見抜く警察 (Discriminator) の関係で表されます。
						偽装者は
							できるだけ本物の紙幣に近い偽装紙幣を作り出すことで、
							警察の目を騙そうとします。
						逆に、警察も
							目利きスキルを上げて
							より本物の紙幣か偽物の紙幣かを見抜こうとします。
						# コンセプトの理解は色々..
						#	警察と偽札作者とか
						#	師匠と弟子とか
					GAN では Generator はできるだけ本物（オリジナル）に近い画像を生成し、
						Discriminator はそれが本物の画像か否かを判定する
						ような構造をしています。
							つまりこの関係は、イタチごっこの関係にあり、
								よりツワモノの敵と競い合うことでスキルを高めていきます。
				GAN では、偽装者 (Generator) の方に関心があり、
					より本物に近い画像などを生成することを目標としています。
					Generative Adversarial Nets (GAN) が
					「敵対生成ネットワーク」という呼び名になっているのも、
					この競い合いのことを言っています。

				GAN では入力として
					"ノイズ" や "潜在変数" と呼ばれる乱数 (Noise) を決め、
						偽物の画像 (Fake) を生成します。
					Discriminator は生成された画像
						# Fake である可能性と
						# Real である可能性があって
						を入力として受け取り、
							それが Fake であるか Real であるのかを判別します。

	[Generatorの仕組み]
		まず Generator からですが
			これは一様分布や正規分布 (ガウス分布とも呼ばれる) から、取り出してきた
			潜在変数 (Noise) を入力します。
				DCGAN の論文では 64*64*3 の画像の生成に
					100 次元の潜在変数を使っています。
					# 潜在変数 (Noise) の使い方とは??
					# 	<= ある少ない変数から情報を生成して
					#		その生成したものに対して
					#		下された判定が限りなく Real になる様に
					#		生成する情報の精度を上げてゆく
					#			# <= 偽を現物に近づけてゆく
					#			!! 最終的に
					#			!!	気づいたらこの gene ってたものって特徴だよね
					#			!! 	という感じなのか??
			この潜在変数を入力として、
				それを転置畳み込み層へ送ります。
					# Transposed Convolution
					# 逆畳み込み ( Deconvolution )と呼ばれることもある。	
					転置畳み込みについては
						ニューラルネットワークにおける Deconvolution に記述がありますが
						少し解説を加えます。
							次の図は転置畳み込みの動作を示した具体的なイメージ図..
								# 参考元参照..
								簡単に言うと
								特徴から元画像を復元するようなことを行っています。
							図では、2*2の画像を2倍に拡大 (2x2のアップサンプリング) して
								3*3 の畳み込みを掛けます。
								これが基本的な転置畳み込みの動作です。
								# 見た感じからいうと、
								#	入力を up sampling して
								#	少ないもの (入力情報) から
								#	大きなもの (生成したい画像) を作ってしまう感じ
								#		# そいつ (大きくしたもの) に対して
								#		# 	畳み込み演算を噛ませるのが
								#		#	現状いまいちよくわからないけど..
								#		入力が設計からして小さいので
								#		情報が圧縮された形になり
								#		どんなものを入力すると
								#		本物 (Real) に近い (と判定される) 画像ができるか?
								#			を回数重ねて学習してゆく感じなのかな (予想)
							しかし、今回は畳み込みの前にパディングをしています。
								# 本当の畳み込みの方
								#	転移ではない畳み込み
								理由は、畳み込みを行うとサイズが小さくなってしまい
									転置畳み込みで拡大した効果を得にくいということと
									その方が、最終的な目標サイズに合わせやすいからです
										( 2*2 の転置畳み込みだと単純にサイズが2倍になる)
		Generator の実装でも
			アップサンプリングをした後、
			畳込みを行っていますが
				結局は転置畳み込み層と同じ動作をしています。
			noise_shape=(self.z_dim,) は "潜在変数の次元数" の指定。
			また、MNIST (28*28*1) と異なり
				著者の使う "キルミーベイベーデータセット" は
					それぞれ 128*128*3 の画像であるので
						始めのノード数は 32*32*128 となっています。
							128 の部分は任意ですが
							32*32 は必然です。
								理由は、転置畳み込みを 2回行っているからで
									32*32 -> 64*64 -> 128*128
									の様にサイズが変化していくことを見越して
									設定する必要があります
										!! Conv2D の padding='same'
										!! 	となっているのに注意。
										# てかこれ自分で計画してモデル組む感じなのか..
										#	ちょっとレベル高いな..
			また、もう一点違う点は
				最終の畳み込みフィルタが 3枚であるということで
				これは画像のチャネル数と一致させる必要があります。

	[潜在変数 (generator への入力) ]
		次に Generator の入力である潜在変数って何か? について

		潜在変数（Generatorの入力）
			潜在変数 (Latent Variable) というのは、
				潜在空間 (Latent space) の中にある変数のことを言っていて
			じゃあ潜在空間って何か
				というと、
					自己符号化器 (Autoencoder) の
					折り返し地点 (Bottleneck) のところです。
				潜在変数は解釈的には「入力データの別表現」と捉えることができます
					# 参考の絵を見ると
					#	Encoder と Decoder のちょうど真ん中 ??
			潜在変数（Noise, Latent variable）は
				自己符号化器のデコーダ (Decoder) の部分の入力であり、
					画像を復元、生成するための "素" であることがわかります。
						Generator は Decoder とほぼ役割は同じです。
						# 通常、我々がトレーニングする CNN は
						# 	Encoder としての役割
						#	# を果たせる様に学習させるという感じ?
				つまり、潜在変数 (Noise) の次元というのは
					自己符号化器でいうところの
						Encoder によって "どれだけの次元になっていることにするのか"
						に当たります。(GAN に Encoder はありませんが)
						# つまり、遡上的なのだけれど
						#	通常の (C)NN などによる Encode が施され
						#		入力 (画像) が
						#			特徴 (本質, であるかでないかをわかつ為の情報) と
						#			それ以外に分離される
						#		この "特徴" がどれくらいかの次元で表現される (はず)
						#			なのだけれど、いくらかわからないので
						#			100だと仮定して GAN を作る
						#			# hyper-parameter になっている
						#			という設計なのだろう..
			"潜在空間" は言わば "概念" みたいなもので
				その中の一つのベクトルである潜在変数は
					一つの概念みたいなものだと解釈できます。
				なので、潜在変数を足したり引いたりすることで、
					概念の足し引きができるんです！
						!! 画像そのものを足し引き (合成など) しているのではなく、
						!! 	潜在変数を足し引きしているという点に注意

	[Discriminatorの仕組み]
		Discriminator は単純にクラス分類を行う識別器として動作します。

		入力には
			Generator からの生成画像 (Fake) と
			オリジナルの画像 (Real) の 2種類があります。

			Discriminator が行う分類は
				「それ (入力) が Fake か Real かを判別すること」です。

		正直 Discriminator は (C)NN なので
			全体を通して行っていることの解説は不要。
				今回は 2値分類なのでシグモイド関数を出力層の活性化関数に使用しています。
				また、DCGAN の Discriminator の実装では以下のような特徴があります。
					* 中間層以外の活性化関数に LeakyReLU を用いる
					* BatchNormalization を頻繁にいれる
					* プーリング層の代わりに stride=2 の畳み込み層を使う
					* 全結合層をなくす
					# そうなんだ..
					#	なぜ??
					#	cf. 論文
					#		https://arxiv.org/abs/1511.06434
	[学習方法]
		[Generator の学習]
			Generator の学習では
				入力は、潜在変数 (Noise) で
				目標は「本物」か「偽物」かの正解ラベルです。
				!! 画像が目標ではありません。
				!!	Generator の行いたいこととしては、
				!!		Discriminator に
				!!			「本物」と判定されるような「偽物」画像を生成することです。
				!! Generator の生成画像を Discriminator に入力して、
				!! 	本物 ( = 1 ) と判定されることを目指します。
				なので、Generator の学習工程としては
					Generator と Discriminator とを組み合わせた
						Combined_model を学習させることになります。
-- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< --
					Noise
				(Latent variable)
					|
					v
				+-----------+
				| Generator |  <= 学習する対象
				+-----------+
					|
					v
				Fake image			Real image
					|					|
					+-------------------+
							|
							v
						Desctiminator  # Generator 学習時, 重みは凍結
							|
							v
						 0 (Fake) / 1 (Real)
-- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< ---- 8< --
   	  	   	  	   	この時、Discriminator のパラメータは固定し、
						Discriminator は学習させないようにします
							# Generatorの学習なので
							#	当然といえば、当然..
						また Generator にとっては
							「生成画像全てが『本物』として
								Discriminator に判断されることを望んでいる」ので
								全ての正解ラベルは 1 (Real) になります。

		[Discriminatorの学習]
			Discriminator の学習では、ミニバッチ学習を行う場合
				ミニバッチの半分を「本物」
				もう半分を「偽物」にして学習を行います。
					!! ただし、この (ミニ) ミニバッチをミックスして学習させるのではなく
					!! 	別々に (ミニ) ミニバッチ学習を行います。
						偽物 (Fake) の学習を行い、
						その次に続けて本物 (Real) の学習を行います。
					合わせて学習させる方法もあるようですが
						今回の場合 Discriminator には
							BatchNormalization 層を入れているので
							合わせてしまうと Fake と Real がまとめて正規化されてしまい
							悪い方向に行ってしまう可能性があるので
							Fake と Realを分けて学習させるほうが無難といえます。
								# 悪い方向??
								#	Normalization するとどんな悪さをする??
			これまでは Discriminator に 2つの方向から入力があるように描かれていましたが
				実際に Discriminator の入り口は一つ
					# ノード数の意味ではありません
					#	データの受け入れ口の話です
				つまり Discriminator は Fake / Real どちらの方向から入力されたのか
					を知る術はありません。
			Generator では、全ての正解ラベルに 1 を割り当てましたが
			Discriminaor は「本物」のみ 1 ( Real ), 「偽物」には 0 ( Fake ) を割り当てる


[実装]
	[参考]
		cf. 今さら聞けないGAN（1）　基本構造の理解
			https://qiita.com/triwave33/items/1890ccc71fab6cbca87e

	[孫引き]
		Generative Adversarial Networks(GAN)を勉強して、kerasで手書き文字生成する
			http://yusuke-ujitoko.hatenablog.com/entry/2017/05/08/010314
		はじめてのGAN
			https://elix-tech.github.io/ja/2017/02/06/gan.html

	[作業]
		-> memo2.txt
